- [生产端](#生产端)
  - [数据丢失场景](#数据丢失场景)
  - [解决](#解决)
- [kakfa](#kakfa)
  - [服务端消息丢失场景](#服务端消息丢失场景)
  - [解决](#解决-1)
- [消费端](#消费端)
  - [消息丢失场景](#消息丢失场景)
  - [解决](#解决-2)

# 生产端

## 数据丢失场景

为了提高吞吐量，生产端**异步发送消息**的情况下，会先存储再本地缓存中，当缓冲区大小、时间间隔到达会触发send操作，发送消息；

1、生产端宕机，会导致缓冲区的数据丢失；

2、ACK策略过低；(网络因素)

## 解决
- **数据一致性要求高，使用同步发送消息**：最少一次的实现；
- 生产端使用Kafka事务消息；保证精准一次；
- **存储到中间介质**，如：发送失败的消息转储，另外进行重试(前提实现幂等Kafka事务)；或告警；
- ACK策略采用 >= 1

# kakfa

## 服务端消息丢失场景

1、**Kafka是异步落盘**：kafka接收到消息，只要数据写入PageCache中，就会返回ACK，不需要等待落；**如果pageCache落盘前宕机，会发生消息丢失的现象**；概率很小；

## 解决

解决：服务端保证消息可靠一般通过副本机制：
- 可用选择落盘策略，降低这两个参数，提高数据一致性：
  - `log.flush.interval.messages = 10000`，设置多少条消息，触发一次刷盘操作；
  - `log.flush.interval.ms = 10000`：间隔多少时间，触发刷盘；

- 增加ISR副本数：`min.insync.replicas` >= 2；

# 消费端
## 消息丢失场景

消费失败，自动提交机制，是基于一定的时间间隔，异步自动提交数据；

## 解决
- **使用手动提交**，并且将**消费逻辑和手动提交绑定在一个事务中**，保证原子性；只有消费成功才提交offset；可用做到：**最少一次**；
  - `enable.auto.commit = false`
- 要实现**精确一次**，还需保证幂等；
